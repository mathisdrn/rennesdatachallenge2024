{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-series model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- modèle [Autoformer](https://huggingface.co/blog/autoformer)\n",
    "- modèle [Time Series Transformer](https://huggingface.co/docs/transformers/model_doc/time_series_transformer)\n",
    "- modèle [Informer](https://huggingface.co/blog/informer)\n",
    "- modèle [Sk Forecast](https://huggingface.co/blog/skforecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1315, 200),\n",
       " (147, 200),\n",
       " 0       2017-08-17\n",
       " 1       2017-08-18\n",
       " 2       2017-08-21\n",
       " 3       2017-08-22\n",
       " 4       2017-08-23\n",
       "            ...    \n",
       " 1310    2022-08-25\n",
       " 1311    2022-08-26\n",
       " 1312    2022-08-29\n",
       " 1313    2022-08-30\n",
       " 1314    2022-08-31\n",
       " Name: date, Length: 1315, dtype: object)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/output_data.csv')\n",
    "\n",
    "# Split dataset in date between 08-2017 to 08-2022 and testing fom 09-2022 to 04-2023\n",
    "\n",
    "X = df[(df['date'] >= '2017-08-01') & (df['date'] < '2022-09-01')].copy()\n",
    "X_test = df[(df['date'] >= '2022-09-01') & (df['date'] < '2023-05-01')].copy()\n",
    "\n",
    "X_date = X['date']\n",
    "X.drop('date', axis = 1, inplace = True)\n",
    "\n",
    "X_date_test = X_test['date']\n",
    "X_test.drop('date', axis = 1, inplace = True)\n",
    "\n",
    "X.shape, X_test.shape, X_date\n",
    "\n",
    "# X = X.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Close_BTC',\n",
       " 'Close_ETH',\n",
       " 'Close_DOGE',\n",
       " 'Close_SHIB',\n",
       " 'Close_DOT',\n",
       " 'Close_BCH',\n",
       " 'Close_SOL',\n",
       " 'Close_ADA',\n",
       " 'Close_MATIC',\n",
       " 'Close_BNB',\n",
       " 'Close_LTC',\n",
       " 'Close_XRP']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract all column name starting by 'close'\n",
    "targets = [col for col in df.columns if col.startswith('Close')]\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e2d4e472cfd4a199befbb210bc06164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='column', options=('date', 'btc_tweet_count', 'eth_tweet_count', 'b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot(column)>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot(column):\n",
    "    if df[column].dtype in ['int64', 'float64']:\n",
    "        sns.boxplot(x=df[column])\n",
    "    else:\n",
    "        sns.countplot(x=df[column])\n",
    "    plt.show()\n",
    "\n",
    "interact(plot, column=df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To write a function to handle outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Get all col containing missing values\n",
    "na_cols = [col for col in X.columns if X[col].isna().sum() > 0]\n",
    "imputer = SimpleImputer(strategy = 'median')\n",
    "\n",
    "print(len(na_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns : 200\n"
     ]
    }
   ],
   "source": [
    "numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "print(f'Numeric columns : {len(numeric_columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "pca = PCA()\n",
    "\n",
    "# Build preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # ('outlier', outlier_remover, outlier_col),\n",
    "        ('imputer', imputer, na_cols),\n",
    "        ('scaler', std, numeric_columns),\n",
    "        ('pca', pca, numeric_columns) \n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataChallenge2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
